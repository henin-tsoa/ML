{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DO NOT USE FOR LOOP ON number of samples N but ONLY ON number of classes C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8c5b3a9bb5f9459df46861b5d84bda38",
     "grade": false,
     "grade_id": "cell-f4572dec0c7469a5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris, load_digits, load_digits\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "def rel_error(x, y):\n",
    "    \"\"\" returns relative error \"\"\"\n",
    "    return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b19e957d3826dd3977f54f428a8744d6",
     "grade": false,
     "grade_id": "cell-d82471ddcebf7ede",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "data = load_iris()\n",
    "X_train, y_train = data.data, data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f5735812b7d43eb37d2bd53c84670597",
     "grade": false,
     "grade_id": "cell-212a715c4b2f4e77",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_priors(X, y):\n",
    "    \"\"\"\n",
    "    Prior probability for each class \n",
    "    \n",
    "    Inputs:\n",
    "    - X: array of shape (N, D) \n",
    "    - y: array of shape (N,) \n",
    "\n",
    "    Returns:\n",
    "    - priors : array of shape (C,)\n",
    "    \"\"\"\n",
    "    C = (np.max(y) + 1)\n",
    "    N = len(y)\n",
    "    priors = np.zeros(C)\n",
    "    temp = np.bincount(y)\n",
    "    #priors = np.bincount(y)\n",
    "    #return (1 / N) * priors\n",
    "    for i in range(C):\n",
    "        priors[i] = temp[i] / N\n",
    "    return priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4595f1d0682daf1d642222e34ca7546f",
     "grade": true,
     "grade_id": "cell-25707d195d3be37b",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "sk_model = QuadraticDiscriminantAnalysis()\n",
    "sk_model.fit(X_train, y_train)\n",
    "\n",
    "priors = compute_priors(X_train, y_train)\n",
    "error = rel_error(sk_model.priors_, priors)\n",
    "print(error)\n",
    "assert  error < 1e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "80987a776d96e04af5c7a0922be6fc7b",
     "grade": false,
     "grade_id": "cell-a4f5a8d209b51a14",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_means(X, y):\n",
    "    \"\"\"\n",
    "    Mean estimate for each class, NO FOR LOOP ON number of samples N but ONLY ON number of classes C\n",
    "    \n",
    "    Inputs:\n",
    "    - X: array of shape (N, D) \n",
    "    - y: array of shape (N,) \n",
    "\n",
    "    Returns:\n",
    "    - means : array of shape (C, D)\n",
    "    \"\"\"\n",
    "    N, D = X.shape    \n",
    "    C = (np.max(y) + 1)\n",
    "    means = np.zeros((C, D))\n",
    "    \n",
    "    I = np.zeros(N)\n",
    "    I = y\n",
    "    Nc = np.bincount(y)\n",
    "    zeros = np.zeros(N)\n",
    "    ones = np.ones(N)\n",
    "    temp = np.zeros(X.shape)\n",
    "\n",
    "    for i in range(C):\n",
    "        I = np.where(y == i, ones, zeros)\n",
    "        temp = np.transpose(np.full((D,N), I)) * X\n",
    "        means[i] = (1 / Nc[i]) * np.sum(temp, axis=0)\n",
    "    return means\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8c5139bd849307229ab94c6dc869516b",
     "grade": true,
     "grade_id": "cell-1ea0c5a7199f1d21",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.372722659314906e-17\n"
     ]
    }
   ],
   "source": [
    "sk_model = QuadraticDiscriminantAnalysis()\n",
    "sk_model.fit(X_train, y_train)\n",
    "\n",
    "means = compute_means(X_train, y_train)\n",
    "error = rel_error(sk_model.means_, means)\n",
    "print(error)\n",
    "assert  error < 1e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6d440cdafa2d4b166c5220793a35fcf7",
     "grade": false,
     "grade_id": "cell-f1401a628db797ef",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_sigmas_gda(X, y, means):\n",
    "    \"\"\"\n",
    "    Covariance estimate for each class, NO FOR LOOP ON number of samples N but ONLY ON number of classes C\n",
    "    DO NOT USE np.cov\n",
    "    Inputs:\n",
    "    - X: array of shape (N, D) \n",
    "    - y: array of shape (N,) \n",
    "    - means: array of shape (C, D)\n",
    "\n",
    "    Returns:\n",
    "    - covariances : array of shape (C, D, D)\n",
    "    \"\"\"\n",
    "    N, D = X.shape    \n",
    "    C = (np.max(y) + 1)\n",
    "    covariances = np.zeros((C, D, D))\n",
    "    \n",
    "    classmean = np.zeros(X.shape)\n",
    "    I = np.zeros(N)\n",
    "    I_2d = np.zeros(X.shape)\n",
    "    zeros = np.zeros(N)\n",
    "    ones = np.ones(N)\n",
    "    temp = np.zeros(X.shape)\n",
    "    Nc = np.bincount(y)\n",
    "    for c in range(C):\n",
    "        I = np.where(y == c, ones, zeros)\n",
    "        I_2d = np.transpose(np.full((D,N), I))\n",
    "        classmean = np.full((N, D), means[c])\n",
    "        temp = I_2d * (X - classmean)\n",
    "        covariances[c] =  (np.transpose(temp) @ temp)\n",
    "        covariances[c] *= 1 / (Nc[c] - 1)\n",
    "    return covariances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d4a27ecc6bbc72e72cfebaffd3ede565",
     "grade": true,
     "grade_id": "cell-6b136fdb522b6eff",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.920351755031412e-16\n"
     ]
    }
   ],
   "source": [
    "sk_model = QuadraticDiscriminantAnalysis(store_covariance=True)\n",
    "sk_model.fit(X_train, y_train)\n",
    "\n",
    "covariances = compute_sigmas_gda(X_train, y_train, sk_model.means_)\n",
    "error = rel_error(np.asarray(sk_model.covariance_), covariances)\n",
    "print(error)\n",
    "assert  error < 1e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "824613ff0ad0e3acb8e67b499598fbba",
     "grade": false,
     "grade_id": "cell-9970ad744b99041a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_sigma_lda(X, y, means):\n",
    "    \"\"\"\n",
    "    Covariance estimate for LDA, NO FOR LOOP ON number of samples N but ONLY ON number of classes C\n",
    "    DO NOT USE np.cov\n",
    "    Inputs:\n",
    "    - X: array of shape (N, D) \n",
    "    - y: array of shape (N,) \n",
    "    - means: array of shape (C, D)\n",
    "\n",
    "    Returns:\n",
    "    - covariance : array of shape (D, D)\n",
    "    \"\"\"\n",
    "    N, D = X.shape    \n",
    "    C = (np.max(y) + 1)\n",
    "    covariance = np.zeros((D, D))\n",
    "    \n",
    "    classmean = np.zeros(X.shape)\n",
    "    I = np.zeros(N)\n",
    "    I_2d = np.zeros(X.shape)\n",
    "    zeros = np.zeros(N)\n",
    "    ones = np.ones(N)\n",
    "    temp = np.zeros(X.shape)\n",
    "    for c in range(C):\n",
    "        I = np.where(y == c, ones, zeros)\n",
    "        I_2d = np.transpose(np.full((D,N), I))\n",
    "        classmean = np.full((N, D), means[c])\n",
    "        temp = I_2d * (X - classmean)\n",
    "        covariance +=  (np.transpose(temp) @ temp)\n",
    "    covariance *= 1 / N\n",
    "    return covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a95472e963297e49709fc0b8c212e341",
     "grade": true,
     "grade_id": "cell-686b35c7c584416e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0823081332523129e-16\n"
     ]
    }
   ],
   "source": [
    "sk_model = LinearDiscriminantAnalysis(store_covariance=True)\n",
    "sk_model.fit(X_train, y_train)\n",
    "\n",
    "covariances = compute_sigma_lda(X_train, y_train, sk_model.means_)\n",
    "error = rel_error(np.asarray(sk_model.covariance_), covariances)\n",
    "print(error)\n",
    "assert  error < 1e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "83b0c0ed8697c9ae414131f3918c0037",
     "grade": false,
     "grade_id": "cell-17c0ce2515e2fc7c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_log_posterior_lda(X, C, priors, means, covariance):\n",
    "    \"\"\"\n",
    "    Covariance log posterior for each class and observation, \n",
    "    NO FOR LOOP ON number of samples N but ONLY ON number of classes C\n",
    "    DO NOT USE scipy or np multivariate gaussian\n",
    "    Inputs:\n",
    "    - X: array of shape (N, D) \n",
    "    - y: array of shape (N,) \n",
    "    - C: number of classes\n",
    "    - priors : array of shape (C,)\n",
    "    - means : array of shape (C, D)\n",
    "    - covariance : array of shape (D, D)\n",
    "\n",
    "    Returns:\n",
    "    - log_posterior : array of shape (N, C)\n",
    "    \"\"\"\n",
    "    N, D = X.shape    \n",
    "    log_posterior = np.zeros((N, C))\n",
    "    W = np.zeros((C,D))\n",
    "    b = np.zeros(C)\n",
    "    \n",
    "    priors_N = np.zeros(N)\n",
    "    diff = np.zeros(X.shape)\n",
    "    classmean = np.zeros(X.shape)\n",
    "    temp = np.zeros((N, D))\n",
    "    for c in range(C):\n",
    "        priors_N = np.full(N, priors[c])\n",
    "        classmean = (np.full((N, D), means[c]))\n",
    "        diff = X - classmean\n",
    "        temp = diff @ np.linalg.inv(covariance)\n",
    "        log_posterior[:, c] = np.sum(temp * diff, axis=1)\n",
    "        log_posterior[:, c] = np.log(priors_N) - (1 / 2.0) * log_posterior[:, c]\n",
    "    return log_posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3bb8777a126866cace4cb4d1b73225f5",
     "grade": false,
     "grade_id": "cell-7a43326dd032e8b4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# NO TEST FOR LOG-POSTERIOR LDA. Mitambatra eo ambany ny test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e2ed41a12624f40c8eabd8a1bac44cb4",
     "grade": false,
     "grade_id": "cell-cc5e3a7eddeb02ad",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_log_posterior_gda(X, C, priors, means, covariances):\n",
    "    \"\"\"\n",
    "    Covariance log posterior for each class and observation, \n",
    "    NO FOR LOOP ON number of samples N but ONLY ON number of classes C\n",
    "    DO NOT USE scipy or np multivariate gaussian\n",
    "    Inputs:\n",
    "    - X: array of shape (N, D) \n",
    "    - y: array of shape (N,) \n",
    "    - C: number of classes\n",
    "    - priors : array of shape (C,)\n",
    "    - means : array of shape (C, D)\n",
    "    - covariances : array of shape (C, D, D)\n",
    "\n",
    "    Returns:\n",
    "    - log_posterior : array of shape (N, C)\n",
    "    \"\"\"\n",
    "    N, D = X.shape    \n",
    "    log_posterior = np.zeros((N, C))\n",
    "    \n",
    "    \n",
    "    priors_N = np.zeros(N)\n",
    "    diff = np.zeros(X.shape)\n",
    "    classmean = np.zeros(X.shape)\n",
    "    temp = np.zeros((N, D))\n",
    "    for c in range(C):\n",
    "        priors_N = np.full(N, priors[c])\n",
    "        classmean = (np.full((N, D), means[c]))\n",
    "        diff = X - classmean\n",
    "        temp = diff @ np.linalg.inv(covariances[c])\n",
    "        log_posterior[:, c] = np.sum(temp * diff, axis=1)\n",
    "        log_posterior[:, c] = np.log(priors_N) - (1 / 2.0) * log_posterior[:, c] \n",
    "        log_posterior[:, c] -= (1 / 2.0) * np.log(np.linalg.det(covariances[c]))\n",
    "    return log_posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "01c0afab4af1700e0a0fc48dd1118bdd",
     "grade": true,
     "grade_id": "cell-d58bf74c60153098",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.605541792973586e-14\n"
     ]
    }
   ],
   "source": [
    "sk_model = QuadraticDiscriminantAnalysis(store_covariance=True)\n",
    "sk_model.fit(X_train, y_train)\n",
    "\n",
    "C = (np.max(y_train) + 1)\n",
    "log_posterior = compute_log_posterior_gda(X_train, C, sk_model.priors_, sk_model.means_, sk_model.covariance_)\n",
    "error = rel_error(np.asarray(sk_model._decision_function(X_train)), log_posterior)\n",
    "print(error)\n",
    "assert  error < 1e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fea4a371e372fa034dcbf73d579c3358",
     "grade": false,
     "grade_id": "cell-f5cbad4c325e856e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class ProbClassifier():\n",
    "    def fit(self, X, y):\n",
    "        pass\n",
    "    \n",
    "    def compute_log_posterior(self, X):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X):\n",
    "        log_post = self.compute_log_posterior(X)\n",
    "        return np.argmax(log_post, axis=1)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        log_post = self.compute_log_posterior(X)\n",
    "        return np.exp(log_post) / np.sum(np.exp(log_post), axis=1)[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c234be9d70fd14a4551b6fcbf8de7ea5",
     "grade": false,
     "grade_id": "cell-1bbbe43fcaed8c4e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class LDA(ProbClassifier):\n",
    "    def __init__(self):\n",
    "        self.priors = None\n",
    "        self.means = None\n",
    "        self.cov = None\n",
    "        self.C = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.C = (np.max(y) + 1)\n",
    "        self.priors = compute_priors(X, y)\n",
    "        self.means = compute_means(X, y)\n",
    "        self.cov = compute_sigma_lda(X, y, self.means)\n",
    "    \n",
    "    def compute_log_posterior(self, X):\n",
    "        return compute_log_posterior_lda(X, self.C, self.priors, self.means, self.cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "470a4776ad0f7dd0fa6df62af2985724",
     "grade": true,
     "grade_id": "cell-103960c9425d1e47",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy scikit-learn :  0.98\n",
      "Your Accuracy :  0.98\n"
     ]
    }
   ],
   "source": [
    "sk_model = LinearDiscriminantAnalysis(store_covariance=True)\n",
    "sk_model.fit(X_train, y_train)\n",
    "sk_pred = sk_model.predict(X_train)\n",
    "\n",
    "lda = LDA()\n",
    "lda.fit(X_train, y_train)\n",
    "pred = lda.predict(X_train)\n",
    "\n",
    "assert (sk_pred == pred).all()\n",
    "print(\"Accuracy scikit-learn : \", accuracy_score(y_train, sk_pred))\n",
    "print(\"Your Accuracy : \", accuracy_score(y_train, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2c02ef4c722a12c047cdd79a33b701bf",
     "grade": false,
     "grade_id": "cell-a86acf06e6c80728",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class QDA(ProbClassifier):\n",
    "    def __init__(self):\n",
    "        self.priors = None\n",
    "        self.means = None\n",
    "        self.cov = None\n",
    "        self.C = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.C = (np.max(y) + 1)\n",
    "        self.priors = compute_priors(X, y)\n",
    "        self.means = compute_means(X, y)\n",
    "        self.cov = compute_sigmas_gda(X, y, self.means)\n",
    "    \n",
    "    def compute_log_posterior(self, X):\n",
    "        return compute_log_posterior_gda(X, self.C, self.priors, self.means, self.cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8b7e49782d08f05716006eaa10b9483f",
     "grade": true,
     "grade_id": "cell-407cb9988a114256",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy scikit-learn :  0.98\n",
      "Your Accuracy :  0.98\n"
     ]
    }
   ],
   "source": [
    "sk_model = QuadraticDiscriminantAnalysis(store_covariance=True)\n",
    "sk_model.fit(X_train, y_train)\n",
    "sk_pred = sk_model.predict(X_train)\n",
    "\n",
    "qda = QDA()\n",
    "qda.fit(X_train, y_train)\n",
    "pred = qda.predict(X_train)\n",
    "\n",
    "assert (sk_pred == pred).all()\n",
    "print(\"Accuracy scikit-learn : \", accuracy_score(y_train, sk_pred))\n",
    "print(\"Your Accuracy : \", accuracy_score(y_train, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7666654f5e7cfcd44a8c2dc0291c0ed9",
     "grade": true,
     "grade_id": "cell-1d95b01b2541d240",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.157450494397167e-14\n"
     ]
    }
   ],
   "source": [
    "sk_model = QuadraticDiscriminantAnalysis(store_covariance=True)\n",
    "sk_model.fit(X_train, y_train)\n",
    "sk_pred = sk_model.predict_proba(X_train)\n",
    "\n",
    "qda = QDA()\n",
    "qda.fit(X_train, y_train)\n",
    "pred = qda.predict_proba(X_train)\n",
    "\n",
    "error = rel_error(pred, sk_pred)\n",
    "print(error)\n",
    "assert error < 1e-12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Bernouilli Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_digits()\n",
    "X_train2, y_train2 = data.data, data.target\n",
    "X_train2_transf = Binarizer().fit_transform(X_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "70742cc3e580d8bfdbf0b9de07a87912",
     "grade": false,
     "grade_id": "cell-d5b51da0e0b8dcc1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class BernouilliNaiveBayes(ProbClassifier):\n",
    "    def __init__(self):\n",
    "        self.priors = None\n",
    "        self.C = None\n",
    "        self.theta = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Estimate the parameter theta\n",
    "        NO FOR LOOP ON number of samples N but ONLY ON number of classes C\n",
    "        DO NOT USE scipy or np density\n",
    "        \"\"\"\n",
    "        N, D = X.shape\n",
    "        self.C = (np.max(y) + 1)\n",
    "        self.theta = np.zeros((D, self.C))\n",
    "        self.priors = np.zeros(self.C)\n",
    "        Nc = np.bincount(y)\n",
    "        self.priors = Nc / N\n",
    "        for c in range(self.C):\n",
    "            self.theta[:, c] = np.sum(X[y == c], axis=0) / Nc[c]\n",
    "    \n",
    "    def compute_log_posterior(self, X):\n",
    "        N, D = X.shape\n",
    "        log_post = np.zeros((N,self.C))\n",
    "        # YOUR CODE HERE\n",
    "        #raise NotImplementedError()\n",
    "        classprior = np.zeros(N)\n",
    "        classtheta = np.zeros(X.shape)\n",
    "        X_inv = np.zeros(X.shape)\n",
    "        X_inv = np.where(X == 1, 0, 1)\n",
    "        for c in range(self.C):\n",
    "            classprior = np.full(N, self.priors[c])\n",
    "            classtheta = np.full(X.shape, self.theta[:, c])\n",
    "            log_post[:, c] = np.log(classprior) + np.sum(np.log((X * classtheta) +  X_inv * (1 - classtheta)+ 1e-8), axis=1) \n",
    "        return log_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7fa098602d1a9e4c9cdca9cf73180a44",
     "grade": true,
     "grade_id": "cell-f960b1ec2ce34b3d",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy scikit-learn :  0.8636616583194212\n",
      "Your Accuracy :  0.8742348358375069\n"
     ]
    }
   ],
   "source": [
    "sk_model = BernoulliNB()\n",
    "sk_model.fit(X_train2_transf, y_train2)\n",
    "sk_pred = sk_model.predict(X_train2_transf)\n",
    "\n",
    "model = BernouilliNaiveBayes()\n",
    "model.fit(X_train2_transf, y_train2)\n",
    "pred = model.predict(X_train2_transf)\n",
    "\n",
    "sk_acc = accuracy_score(y_train2, sk_pred)\n",
    "model_acc = accuracy_score(y_train2, pred)\n",
    "print(\"Accuracy scikit-learn : \", sk_acc)\n",
    "print(\"Your Accuracy : \", model_acc)\n",
    "assert sk_acc - model_acc < 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2d67f1b1383503b5e5203c265f59b99d",
     "grade": false,
     "grade_id": "cell-186f17a680895047",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class GaussianNaiveBayes(ProbClassifier):\n",
    "    def __init__(self):\n",
    "        self.priors = None\n",
    "        self.C = None\n",
    "        self.mu = None\n",
    "        self.sigma = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Estimate the parameters mu and sigma\n",
    "        NO FOR LOOP ON number of samples N but ONLY ON number of classes C\n",
    "        DO NOT USE scipy or np density\n",
    "        \"\"\"\n",
    "        N, D = X.shape\n",
    "        self.C = (np.max(y) + 1)\n",
    "        self.sigma = np.zeros((D, self.C))\n",
    "        self.mu = np.zeros((D,self.C))\n",
    "        self.priors = np.zeros(self.C)\n",
    "        \n",
    "        I = np.zeros(N)\n",
    "        full_mu = np.zeros(X.shape)\n",
    "        I_2d = np.zeros(X.shape)\n",
    "        zeros = np.zeros(N)\n",
    "        ones = np.ones(N)\n",
    "        \n",
    "        Nc = np.bincount(y)\n",
    "        \n",
    "        self.priors = Nc / N\n",
    "        for c in range(self.C):\n",
    "            self.mu[:, c] = np.sum(X[y == c], axis=0) / Nc[c]\n",
    "        for c in range(self. C):\n",
    "            I = np.where(y == c, ones, zeros)\n",
    "            I_2d = np.transpose(np.full((D,N), I))\n",
    "            full_mu = np.full((N, D), self.mu[:, c])\n",
    "            self.sigma[:, c] = np.sum(I_2d * ((X - full_mu) ** 2), axis=0) / Nc[c]\n",
    "            \n",
    "    def compute_log_posterior(self, X):\n",
    "        N, D = X.shape\n",
    "        log_post = np.zeros((N,self.C))\n",
    "        classprior = np.zeros(N)\n",
    "        \n",
    "        for c in range(self.C):\n",
    "            classprior = np.full(N, self.priors[c])\n",
    "            log_post[:, c] = classprior \n",
    "            log_post[:, c] -= (1 / 2.) * np.sum(np.log(2 * np.pi * self.sigma[:, c]) + (((X - self.mu[:, c])**2)/self.sigma[:, c]), axis=1)\n",
    "        return log_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8d510e4b6069f1d0549606f4a4a12416",
     "grade": true,
     "grade_id": "cell-7ac37952b1e80482",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy scikit-learn :  0.96\n",
      "Your Accuracy :  0.96\n"
     ]
    }
   ],
   "source": [
    "sk_model = GaussianNB()\n",
    "sk_model.fit(X_train, y_train)\n",
    "sk_pred = sk_model.predict(X_train)\n",
    "\n",
    "model = GaussianNaiveBayes()\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_train)\n",
    "\n",
    "sk_acc = accuracy_score(y_train, sk_pred)\n",
    "model_acc = accuracy_score(y_train, pred)\n",
    "print(\"Accuracy scikit-learn : \", sk_acc)\n",
    "print(\"Your Accuracy : \", model_acc)\n",
    "assert sk_acc - model_acc < 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
